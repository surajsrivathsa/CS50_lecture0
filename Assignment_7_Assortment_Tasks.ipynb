{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 7: Assortment_Tasks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ukg40jDE7OWr",
        "l3gcdqdV23hs",
        "Vc201e0hQgKP",
        "wWQu9B9K3qDe",
        "Bn3id5U2GL2c",
        "NAvvvW93PcDi",
        "Szsy76yOP9B_",
        "O4S3KzuIx0OY",
        "WSd8a3bkNANy",
        "OWWwyMvIGdKi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajsrivathsa/ovgu_deeplearning/blob/master/Assignment_7_Assortment_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_9dD0WiFPt",
        "colab_type": "text"
      },
      "source": [
        "Deep Learning programming task\n",
        "\n",
        "**Assignment 7:** Assortment Programming Puzzels\n",
        "\n",
        "**Team members:**\n",
        "1. Sanjeeth Busnur Indushekar: 224133 : sanjeeth.busnur@st.ovgu.de\n",
        "2. Aditya Dey : 230580 : aditya.dey@st.ovgu.de\n",
        "3. Suraj Shashidhar: 230052 : suraj.shashidhar@st.ovgu.de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2zBBkG1r4Wu",
        "colab_type": "text"
      },
      "source": [
        "# Tasks to be done:\n",
        "\n",
        "**Task 5 was not completed, Rest of the tasks were completed**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1p4Kx2OZv8hqXtdspGMcnzdb0PIWFBASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adh3WsE1dmkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59zPOCe1KwKa",
        "colab_type": "code",
        "outputId": "4f4624a5-d3e7-44d2-bcea-a8e5e213d971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import initializers\n",
        "import tensorboard\n",
        "import time\n",
        "from datetime import datetime\n",
        "from keras import backend as K\n",
        "from prepare_data import parse_seq\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0iZWwrneCIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 448 is the longest length sequence there are 31k sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO6eemPNfoat",
        "colab_type": "code",
        "outputId": "b4596e9d-c697-44bb-9f0f-88a9a49f0912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "  print(os.getcwd())\n",
        "  print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F420Gu-7f3x8",
        "colab_type": "code",
        "outputId": "7c88fb82-7c1e-401d-8449-041625be16d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676Zm3kMgNJP",
        "colab_type": "code",
        "outputId": "04891c5c-1edb-4fda-f62c-b5689573dac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "\n",
        "path = '.'\n",
        " \n",
        "files = os.listdir(path)\n",
        "for name in files:\n",
        "    print(name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".config\n",
            "shakespeare_input.txt\n",
            "skp_vocab\n",
            "skp.tfrecords\n",
            "prepare_data.py\n",
            "__pycache__\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD4ciLgJtexg",
        "colab_type": "text"
      },
      "source": [
        "# **Task 1**: \n",
        "Given a 2D tensor of shape (?, n), extract the k (k <= n) highest values for each row into a tensor of shape (?, k). Hint: There might be a function to get the “top k” values of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-J4cTb3tnkt",
        "colab_type": "code",
        "outputId": "d41b3f3b-dd89-4e22-ea41-2892a267de75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_tnsr_t1 = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[16, 16]))\n",
        "input_tnsr_t1"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(16, 16) dtype=float32, numpy=\n",
              "array([[ 0.03599551, -0.14012113,  0.17939186, -0.2241995 , -0.25859192,\n",
              "        -0.11344741, -0.01083392,  0.13301323, -0.00425996, -0.39874047,\n",
              "         0.48727453, -0.3916559 ,  0.10636404,  0.1940137 , -0.06120357,\n",
              "        -0.1483257 ],\n",
              "       [-0.0474022 , -0.16743772, -0.00250254, -0.06109133,  0.08316933,\n",
              "         0.01863756, -0.05121751,  0.33412674,  0.19457917,  0.29651564,\n",
              "         0.07020745,  0.20923188,  0.00870483, -0.3769552 , -0.04677309,\n",
              "         0.00573805],\n",
              "       [ 0.15328243, -0.24259292, -0.08504364, -0.11215784, -0.29976562,\n",
              "        -0.24337359, -0.16631705, -0.32558355,  0.46128425,  0.04590841,\n",
              "         0.1541892 ,  0.43880546,  0.20568156, -0.08913616,  0.21326609,\n",
              "        -0.20274375],\n",
              "       [ 0.11914316, -0.11068519,  0.08054616,  0.1384888 , -0.4070555 ,\n",
              "        -0.15359019, -0.18134585, -0.13427472,  0.08665706, -0.15112805,\n",
              "        -0.35246122,  0.12724638,  0.23564412,  0.15365699,  0.44361848,\n",
              "        -0.0318963 ],\n",
              "       [-0.12159988,  0.30533567,  0.27963844, -0.13012828,  0.158199  ,\n",
              "        -0.43003097, -0.12413856, -0.12815396, -0.5410426 , -0.17840187,\n",
              "        -0.04985639, -0.1287164 ,  0.21000311, -0.14439082, -0.49684426,\n",
              "         0.08406656],\n",
              "       [-0.398143  , -0.06858714,  0.39712387,  0.07989275,  0.5550816 ,\n",
              "        -0.01799726,  0.38147244,  0.09872178,  0.19306247,  0.00394471,\n",
              "         0.04595011,  0.10996946,  0.03740985, -0.25063798, -0.25460982,\n",
              "        -0.0800475 ],\n",
              "       [-0.33026335, -0.12575145,  0.3538438 , -0.10228131,  0.17175575,\n",
              "         0.04236022,  0.51683193,  0.24363707,  0.03984958, -0.55858094,\n",
              "        -0.01875903, -0.33563223, -0.22863497,  0.05605729,  0.05275374,\n",
              "        -0.31284803],\n",
              "       [-0.0329792 ,  0.51508737,  0.3433384 ,  0.05267965,  0.08754467,\n",
              "         0.34444094, -0.0271074 ,  0.10804652, -0.05733987, -0.3667579 ,\n",
              "        -0.1497717 ,  0.1331467 , -0.44410387, -0.1614003 ,  0.04263859,\n",
              "        -0.5156574 ],\n",
              "       [-0.08575854,  0.1046799 , -0.00250481, -0.28353584, -0.2597671 ,\n",
              "         0.26497772,  0.24011938, -0.3312863 ,  0.10938019,  0.03220945,\n",
              "         0.28461596, -0.5596351 , -0.09441783,  0.03003279,  0.30141658,\n",
              "         0.22292627],\n",
              "       [-0.15549837, -0.10356259,  0.2745622 ,  0.03366821,  0.3078747 ,\n",
              "         0.02396099, -0.21808377, -0.31428227, -0.03158466,  0.00648622,\n",
              "         0.3702066 ,  0.16090557, -0.45936942,  0.08510779,  0.06634564,\n",
              "        -0.20882489],\n",
              "       [ 0.03284656, -0.22526962,  0.31158692,  0.03407389,  0.19717547,\n",
              "        -0.18955342, -0.23172402,  0.02742362, -0.19327979,  0.22580129,\n",
              "         0.1405851 ,  0.13871413, -0.31850266,  0.42835367,  0.3826073 ,\n",
              "        -0.08708005],\n",
              "       [ 0.05470961,  0.04344972, -0.07402335, -0.0834235 ,  0.22841172,\n",
              "         0.17389038, -0.06175491, -0.05192101, -0.2478045 ,  0.27436855,\n",
              "        -0.31542608, -0.17261659, -0.12078311, -0.14003323,  0.05400284,\n",
              "         0.20082285],\n",
              "       [-0.08348868,  0.11057246, -0.06852821,  0.44356868, -0.0193938 ,\n",
              "         0.05103404,  0.29710427, -0.23550121,  0.30833662,  0.22182465,\n",
              "        -0.40906855,  0.28277284,  0.25275677,  0.19497044,  0.27428058,\n",
              "        -0.1985552 ],\n",
              "       [ 0.3908865 ,  0.02189935, -0.35727972, -0.10454951, -0.00879371,\n",
              "         0.23989889, -0.24027377, -0.02622779,  0.209177  ,  0.00465783,\n",
              "         0.51057893,  0.0014089 ,  0.33854204, -0.24368365,  0.13900828,\n",
              "         0.04698435],\n",
              "       [-0.48519143, -0.24789953, -0.24016577, -0.20337178,  0.16577944,\n",
              "        -0.0792304 , -0.05961132,  0.13133787,  0.41722775, -0.01335808,\n",
              "         0.12655059,  0.28793982, -0.06722711, -0.13011076, -0.1343599 ,\n",
              "        -0.03430171],\n",
              "       [-0.5385678 , -0.10279894, -0.25838408,  0.07621481,  0.03916979,\n",
              "        -0.00532245, -0.39769292,  0.00944948,  0.26447675, -0.1423614 ,\n",
              "         0.34242094,  0.02436901, -0.07354955, -0.36558914,  0.3917093 ,\n",
              "        -0.32126808]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQbiGm_Xtnqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def topk(inp_tensor, k, sort):\n",
        "  return tf.math.top_k(inp_tensor, k, sort)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et2wfLaxtnh8",
        "colab_type": "code",
        "outputId": "9f395dfb-8f50-4ab4-9453-cf83b73f8657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "topk(input_tnsr_t1, 2, True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TopKV2(values=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=\n",
              "array([[0.48727453, 0.1940137 ],\n",
              "       [0.33412674, 0.29651564],\n",
              "       [0.46128425, 0.43880546],\n",
              "       [0.44361848, 0.23564412],\n",
              "       [0.30533567, 0.27963844],\n",
              "       [0.5550816 , 0.39712387],\n",
              "       [0.51683193, 0.3538438 ],\n",
              "       [0.51508737, 0.34444094],\n",
              "       [0.30141658, 0.28461596],\n",
              "       [0.3702066 , 0.3078747 ],\n",
              "       [0.42835367, 0.3826073 ],\n",
              "       [0.27436855, 0.22841172],\n",
              "       [0.44356868, 0.30833662],\n",
              "       [0.51057893, 0.3908865 ],\n",
              "       [0.41722775, 0.28793982],\n",
              "       [0.3917093 , 0.34242094]], dtype=float32)>, indices=<tf.Tensor: shape=(16, 2), dtype=int32, numpy=\n",
              "array([[10, 13],\n",
              "       [ 7,  9],\n",
              "       [ 8, 11],\n",
              "       [14, 12],\n",
              "       [ 1,  2],\n",
              "       [ 4,  2],\n",
              "       [ 6,  2],\n",
              "       [ 1,  5],\n",
              "       [14, 10],\n",
              "       [10,  4],\n",
              "       [13, 14],\n",
              "       [ 9,  4],\n",
              "       [ 3,  8],\n",
              "       [10,  0],\n",
              "       [ 8, 11],\n",
              "       [14, 10]], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtB6Dp_cvkJe",
        "colab_type": "text"
      },
      "source": [
        "# **Task 2:**\n",
        "Given a tensor of shape (?, n), find the argmax in each row and return a new tensor that contains a 1 in each of the argmax’ positions, and 0s everywhere else.\n",
        "\n",
        "Use the same method used in assigment 6/7\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/sequence_mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nna5LU67GFnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_tensor = tf.random.uniform((10,10),minval=-10, maxval=10, dtype=tf.dtypes.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld0OHGL8vo0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maskMatrix(inp_tensor):\n",
        "  max_indices = tf.TensorArray(tf.dtypes.int64, 0, True)\n",
        "  for x, i in enumerate(tf.math.argmax(inp_tensor, axis= 1).numpy()):\n",
        "    max_indices = max_indices.write(x, [x,i])\n",
        "  values = tf.ones(inp_tensor.shape[0], tf.dtypes.int64)\n",
        "  return tf.sparse.to_dense(tf.sparse.SparseTensor(max_indices.stack(), values, inp_tensor.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2e5u38iDG6H",
        "colab_type": "code",
        "outputId": "4bb380ee-fa0a-449b-dc3c-f7ef6054879c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "maskMatrix(inp_tensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=int64, numpy=\n",
              "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrK_lM-gGNWa",
        "colab_type": "text"
      },
      "source": [
        "# **Task 3**\n",
        "As in 1., but instead of “extracting” the top k values, create a new tensor with shape (?, n) where all but the top k values for each row are zero. Try doing this with a 1D tensor of shape (n,) (i.e. one row) first. Getting it right for a 2D tensor is more tricky; consider this a bonus. Hint: You should look for a way to “scatter” a tensor of values into a different tensor. For two or more dimensions, you need to think carefully about the indices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqPuRXwvGiGe",
        "colab_type": "text"
      },
      "source": [
        "References\n",
        "\n",
        "https://stackoverflow.com/questions/49966402/using-tensorflows-top-k-and-scatter-nd\n",
        "https://stackoverflow.com/questions/52996505/using-scatter-nd-with-top-k-output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmtpBAnxGt7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def topk(inp_tensor, k, sort):\n",
        "  return tf.math.top_k(inp_tensor, k, sort)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ymlkJuPGMhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def extract_top_K(inp_tensor, k):\n",
        "  top_k_values, top_k_indices = topk(inp_tensor, k, True)\n",
        "  num_rows = top_k_indices.shape[0]\n",
        "  row_range = tf.range(num_rows)\n",
        "  row_tensor = tf.tile(row_range[:,None], (1, k))\n",
        "  top_k_row_col_indices = tf.stack([row_tensor, top_k_indices], axis=2)\n",
        "  print(top_k_row_col_indices)\n",
        "  print(top_k_values)\n",
        "  return tf.scatter_nd(top_k_row_col_indices, top_k_values, inp_tensor.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG9Z8U-fGoFj",
        "colab_type": "code",
        "outputId": "936bc399-3a2f-4825-a2d4-9d6176ba491e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "topk_matrix = extract_top_K(inp_tensor, 4)\n",
        "topk_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"stack:0\", shape=(10, 4, 2), dtype=int32)\n",
            "Tensor(\"PartitionedCall:0\", shape=(10, 4), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
              "array([[ 2,  0,  0,  9,  2,  0,  0,  6,  0,  0],\n",
              "       [ 7,  0,  0,  9,  0,  7,  0,  0,  0,  7],\n",
              "       [ 0,  0,  0,  6,  0,  0, -1,  7,  4,  0],\n",
              "       [ 0,  0,  0,  2,  2,  0,  8,  0,  7,  0],\n",
              "       [ 0,  0,  2,  4,  0,  0,  9,  7,  0,  0],\n",
              "       [ 0,  5,  0,  0,  5,  0,  0,  7,  1,  0],\n",
              "       [ 0,  9,  3,  0,  3,  0,  0,  0,  7,  0],\n",
              "       [ 0,  0,  0,  0,  4,  5,  4,  0,  6,  0],\n",
              "       [ 0,  5,  0,  0,  0,  8,  6,  0,  2,  0],\n",
              "       [ 0,  9, -1,  0,  3,  0,  0,  2,  0,  0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nAN5hyOG73i",
        "colab_type": "text"
      },
      "source": [
        "# **Task 4**\n",
        "Implement an exponential moving average. That is, given a decay rate a and an input tensor of length T, create a new length T tensor where new[0] = input[0] and new[t] = a * new[t-1] + (1-a) * input[t] otherwise. Do not use tf.train.ExponentialMovingAverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCDw8FjGoMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ce6b1fa3-2143-459c-d6d4-fbbf548a10bd"
      },
      "source": [
        "inp_tensor2 = tf.random.uniform([10],minval=-10, maxval=10, dtype=tf.dtypes.float32)\n",
        "inp_tensor2\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 1.1139183,  6.127817 ,  1.5861082,  5.5715227,  8.066624 ,\n",
              "       -9.228535 , -7.4225616,  5.852726 ,  0.6180906, -1.3401985],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiZkMKyUAlJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def exp_mov_avg(inp_tensor, a):\n",
        "  a = tf.cast(a, tf.dtypes.float32)\n",
        "  new_tensor = tf.TensorArray(tf.dtypes.float32, size = 0, dynamic_size=True)\n",
        "  new_tensor = new_tensor.write(0, inp_tensor[0])\n",
        "  for t in tf.range(1, inp_tensor.shape[0]):\n",
        "    new_tensor_stack = new_tensor.stack()\n",
        "    new_val = tf.squeeze(tf.add(tf.multiply(a, new_tensor_stack[t-1]), tf.multiply(tf.subtract(1.0,a), inp_tensor[t])))\n",
        "    new_tensor = new_tensor.write(t, new_val)\n",
        "  return new_tensor.stack()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQxA2PPQGoJe",
        "colab_type": "code",
        "outputId": "976453b5-984f-4284-b580-f08b30ab10f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "ema = exp_mov_avg(inp_tensor2, 0.4)\n",
        "ema"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 1.1139183 ,  4.1222577 ,  2.600568  ,  4.383141  ,  6.5932307 ,\n",
              "       -2.8998284 , -5.613468  ,  1.2662485 ,  0.8773538 , -0.45317766],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzgp2GjiHL0v",
        "colab_type": "text"
      },
      "source": [
        "# **Task 5**\n",
        "\n",
        "***Task 5 was not completed***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8QjAwYT87hJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "ce6bb24c-3c60-49c8-e4e6-1109c2b65916"
      },
      "source": [
        "input_tnsr_t5 = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[10, 5]))\n",
        "input_tnsr_t5"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(10, 5) dtype=float32, numpy=\n",
              "array([[ 0.05257481, -0.20466001,  0.2620186 , -0.32746434, -0.37769768],\n",
              "       [-0.16570054, -0.01582395,  0.19427827, -0.00622208, -0.5823977 ],\n",
              "       [ 0.71171   , -0.57205003,  0.15535462,  0.28337514, -0.08939353],\n",
              "       [-0.21664353, -0.06923535, -0.24455844, -0.0036552 , -0.0892296 ],\n",
              "       [ 0.12147658,  0.0272219 , -0.07480796,  0.48802334,  0.28420106],\n",
              "       [ 0.43308884,  0.10254454,  0.30560273,  0.01271421, -0.55057836],\n",
              "       [-0.06831647,  0.00838095,  0.22388332, -0.35432962, -0.12421418],\n",
              "       [-0.16381702, -0.43783572, -0.35546988, -0.24292159, -0.47554523],\n",
              "       [ 0.6737488 ,  0.06705352,  0.22520775,  0.6409164 ,  0.30041716],\n",
              "       [-0.1301917 ,  0.31149507, -0.2961262 ,  0.17401972, -0.16166607]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2gXFwzX9wiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f163793-f39e-466d-cbb1-1f239dbf8f3f"
      },
      "source": [
        "t = tf.constant([[[1, -1, 1], [2, -2, 2]],\n",
        "                 [[3, -3, 3], [-9, 7, 9]],\n",
        "                 [[5, -5, 5], [6, -6, 6]]])\n",
        "tf.shape(t)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 2, 3], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hiU2HnC-Aer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50ea50d3-45b8-437c-e040-257c1336e9da"
      },
      "source": [
        "tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
        "tf.slice(t, [2, 1, 0], [1, 1, 2])  # [[[3, 3, 3],\n",
        "                                   #   [4, 4, 4]]]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 2), dtype=int32, numpy=array([[[ 6, -6]]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDcMBrV8HNac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "e5f71f2f-00b0-4426-9d4e-c4632d212383"
      },
      "source": [
        "tf.slice(input_tnsr_t5, begin=0, size=4, name=None)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-c2b45aa6dcb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tnsr_t5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \"\"\"\n\u001b[0;32m-> 1037\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   9090\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9091\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9092\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9093\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9094\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected begin and size arguments to be 1-D tensors of size 2, but got shapes [] and [] instead. [Op:Slice]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg0iPj__HNgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ema = tf.train.ExponentialMovingAverage(decay=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM7J_wC1HyVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "99159dec-01e7-41f4-9484-241c684bb928"
      },
      "source": [
        "input_tnsr_t5 = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[10, ]))\n",
        "input_tnsr_t5"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=\n",
              "array([ 0.04553112, -0.17724077,  0.22691475, -0.28359243, -0.32709578,\n",
              "       -0.14350088, -0.01370394,  0.16824992, -0.00538848, -0.5043712 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcPfloLRHQRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "324cab45-6cb5-4cab-81a6-fb093ae430bc"
      },
      "source": [
        "training_op = ema.apply([input_tnsr_t5])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:444: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYw_33vcICLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "7b3b1171-6cbc-4ec8-adb2-a85e409fa237"
      },
      "source": [
        "shadow_var0_name = ema.average_name(input_tnsr_t5)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-a6e0d61c738f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshadow_var0_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tnsr_t5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36maverage_name\u001b[0;34m(self, var)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \"\"\"\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_averages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_averages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m     return ops.get_default_graph().unique_name(\n\u001b[1;32m    512\u001b[0m         var.op.name + \"/\" + self.name, mark_as_used=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    579\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;34m\"\"\"The op for this variable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1111\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     raise AttributeError(\n\u001b[0;32m-> 1113\u001b[0;31m         \"Tensor.op is meaningless when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Tensor.op is meaningless when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA1NzYmhHQyx",
        "colab_type": "text"
      },
      "source": [
        "# **Task 6**\n",
        "Given three integer tensors x, y, z all of the same (arbitrary) shape, create a new tensor that takes values from y where x is even and from z where x is odd."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHaRUKq3HbW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.random.uniform([10],minval=0, maxval=10, dtype=tf.dtypes.int32)\n",
        "y = tf.random.uniform([10],minval=0, maxval=10, dtype=tf.dtypes.int32)\n",
        "z = tf.random.uniform([10],minval=0, maxval=10, dtype=tf.dtypes.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTLaoKi1HbTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_tensor_gen(x,y,z):\n",
        "  new_tensor = tf.TensorArray(tf.dtypes.int32, 0, True)\n",
        "  for i in tf.range(x.shape):\n",
        "    if( x[i] % 2 == 0):\n",
        "      new_tensor = new_tensor.write(i, y[i])\n",
        "    else:\n",
        "      new_tensor = new_tensor.write(i, z[i])\n",
        "  return new_tensor.stack()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIX8I1bEHhzg",
        "colab_type": "code",
        "outputId": "6b20088a-0dac-45b1-df9c-ae728ee2d93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_tensor = new_tensor_gen(x,y,z)\n",
        "new_tensor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([5, 4, 9, 8, 0, 5, 6, 8, 2, 8], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhSoR4GyHj1X",
        "colab_type": "text"
      },
      "source": [
        "# **Task 7**\n",
        "\n",
        "Given a tensor of arbitrary and unknown shape (but at least one dimension), return 100 if the last dimension has size > 100, 12 if the last dimension has size <= 100 and > 44, and return 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKB15EdAHozw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.random.uniform([15,20, 6],minval=-10, maxval=10, dtype=tf.dtypes.int32)\n",
        "def fun(inp_tensor):\n",
        "  last_dim = inp_tensor.shape[-1]\n",
        "  print(last_dim)\n",
        "  if last_dim > 100:\n",
        "    return 100\n",
        "  elif (last_dim in tf.range(44,101)):\n",
        "    return 12\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKo_Or4MHoxK",
        "colab_type": "code",
        "outputId": "a53d90e7-28d5-4933-b822-4182f48a56be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(fun(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQXZmViuHzRY",
        "colab_type": "text"
      },
      "source": [
        "# **Task 8**\n",
        "As 7., but also create three global counts (integers), where count i should grow by 1 if condition i happened. Run the function from 7. multiple times to test whether your counting works. Now, add a @tf.function decorator to the function from 7. Does your counter still work? If not, why not? Can you change it so it does work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PUr0DVxHouN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global counters\n",
        "c1 = tf.Variable(0)\n",
        "c2 = tf.Variable(0)\n",
        "c3 = tf.Variable(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R9KbJkKHorZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def fun2(inp_tensor, c1, c2, c3):\n",
        "  last_dim = inp_tensor.shape[-1]\n",
        "  if last_dim > 100:\n",
        "    c1.assign_add(1)\n",
        "    return 100\n",
        "  elif (last_dim in range(44,101)):\n",
        "    c2.assign_add(1)\n",
        "    return 12\n",
        "  else:\n",
        "    c3.assign_add(1)\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE9ZJHYsHool",
        "colab_type": "code",
        "outputId": "72e357ff-0c09-4ef1-ca2f-09673060e13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "x = tf.zeros([1,1,86])\n",
        "print(fun2(x, c1,c2,c3))\n",
        "print(c1)\n",
        "print(c2)\n",
        "print(c3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>\n",
            "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>\n",
            "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jczlZGD9ICLt",
        "colab_type": "text"
      },
      "source": [
        "# **Task 9**\n",
        "Given two 1D tensors of equal length n, create a tensor of shape (n, n) where element i,j is the ith element of the first tensor minus the jth element of the second tensor. No loops! Hint: Tensorflow supports broadcasting much like numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxaTWRuWHol7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.random.uniform([3],minval=0, maxval=10, dtype=tf.dtypes.int32)\n",
        "y = tf.random.uniform([3],minval=0, maxval=10, dtype=tf.dtypes.int32)\n",
        "@tf.function\n",
        "def gen_tensor(t1, t2):\n",
        "  n = t1.shape[0]\n",
        "  return(tf.subtract(tf.reshape(tf.repeat(t1, repeats=n, axis=0), [n,n]), t2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y59qzf1nII5d",
        "colab_type": "code",
        "outputId": "cd2ddfdb-1ce2-4280-b349-1661b6ac3dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "gen_tensor(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 7,  5,  5],\n",
              "       [-1, -3, -3],\n",
              "       [ 6,  4,  4]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R9_lTYaISTY",
        "colab_type": "text"
      },
      "source": [
        "# **Task 10**\n",
        "\n",
        "Implement dot product attention: You are given a sequence of encoder states h of shape batch x time x features and the last decoder state s of shape batch x features. Compute the attention weights alpha where alpha[:, i] is equal to h[:, i] * s where * is the dot product between vectors (in this case we also have a batch dimension so the dot product should be between the corresponding vectors within the batch). That is, alpha should be of shape batch x time and alpha[:, i] should contain the attention weights for encoder time step i."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbaImZXM611b",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1HtmC8xm5QjgwhcSjzKajo4EcIk2lF5bI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQhr3p1AlhWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1d7109b1-86bf-4f96-ac56-addd52e5c5e3"
      },
      "source": [
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "\n",
        "#data.padded_batch\n",
        "#batched_data = data.padded_batch(batch_size = 128, drop_remainder=True)\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200))\n",
        "\n",
        "\n",
        "#batched_categorical_data = data.padded_batch(batch_size=128, padded_shapes=448,padding_values=0, drop_remainder=True)\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "ch_to_ind = {v: k for k, v in ind_to_ch.items()}\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 1, 'C': 2, 'l': 3, '!': 4, '?': 5, 'q': 6, 'f': 7, 't': 8, 'J': 9, 'n': 10, ':': 11, 'i': 12, 'r': 13, 'R': 14, 's': 15, ' ': 16, 'v': 17, 'I': 18, 'V': 19, '-': 20, 'Z': 21, 'X': 22, 'z': 23, 'e': 24, 'U': 25, 'F': 26, 'N': 27, '[': 28, 'm': 29, 'S': 30, 'd': 31, 'O': 32, '3': 33, 'a': 34, ']': 35, 'W': 36, 'c': 37, 'k': 38, 'Y': 39, 'L': 40, 'P': 41, 'w': 42, 'B': 43, \"'\": 44, 'E': 45, 'x': 46, 'H': 47, 'M': 48, 'u': 49, ',': 50, 'y': 51, 'h': 52, 'Q': 53, '&': 54, 'G': 55, 'b': 56, 'D': 57, '$': 58, 'K': 59, 'T': 60, 'o': 61, '.': 62, 'g': 63, 'j': 64, ';': 65, 'A': 66, 'p': 67, '<S>': 0}\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q5tPWbJn_fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batched_vocab_data = data.batch(batch_size=128,drop_remainder=True)\n",
        "batched_onehotencoded_data = new_data.batch(batch_size=128, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYIM5D2uII-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for num, elem in enumerate(data):\n",
        "  if(num == 4):\n",
        "\n",
        "    break;\n",
        "  #print(elem)\n",
        "  #print(\" ====== Creating Labels by taking slices ==========\")\n",
        "  #print(elem[1:])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEngJmv9mnq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehotencode(ds):\n",
        "  \n",
        "  new_data = tf.one_hot(indices = ds, depth = vocab_size)\n",
        "  return new_data;\n",
        "\n",
        "new_data = data.map(onehotencode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6yFCb3Pmq-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "caeb0d08-d02c-4ef2-d645-d6cb8d595f59"
      },
      "source": [
        "cnt = 0\n",
        "for element in data:\n",
        "  cnt = cnt+1\n",
        "print(cnt)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQXDWA1UsN8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_decoder_state_fixed = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,63]))\n",
        "previous_decoder_state_fixed = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,63]))\n",
        "current_encoder_state = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,63]))\n",
        "unscaled_attention_matrix = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,200]))\n",
        "softmax_attention_matrix = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,200]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmhfIJbytcLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "aa6a8bdb-7704-4f4d-f6a4-cff8cf0e6657"
      },
      "source": [
        "previous_decoder_state_fixed"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(128, 63) dtype=float32, numpy=\n",
              "array([[ 0.01473352, -0.05735376,  0.07342789, ...,  0.09645282,\n",
              "         0.0628942 ,  0.18157996],\n",
              "       [-0.01305565, -0.04977272,  0.12497865, ...,  0.05449903,\n",
              "        -0.18177864, -0.06606366],\n",
              "       [ 0.01745264, -0.21106663, -0.03510231, ..., -0.12910882,\n",
              "        -0.07065466, -0.04943841],\n",
              "       ...,\n",
              "       [ 0.07512955,  0.02983235, -0.08212686, ..., -0.03503273,\n",
              "        -0.07772417,  0.12510055],\n",
              "       [ 0.02088889,  0.19565317,  0.06373518, ...,  0.04682589,\n",
              "        -0.07369351, -0.19658963],\n",
              "       [-0.18037029, -0.11600257, -0.01586506, ..., -0.07738629,\n",
              "         0.03209957,  0.07263009]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Lz4T_goK0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3979503d-56c9-45f0-a2f5-8a55ab080093"
      },
      "source": [
        "time_steps=200\n",
        "#Pick the 4th timestep decoder state of dimension [128, 1]\n",
        "for batch_num, (x_batch_train, val_data) in enumerate(zip(batched_onehotencoded_data,batched_vocab_data) ):\n",
        "  print(\"===== batch number: {}\".format(batch_num))\n",
        "  for time_step in range(time_steps-1):\n",
        "    if(time_step == 4):\n",
        "      previous_decoder_state_fixed = val_data[:, time_step]\n",
        "    #encoder_state_at_current_time_step = x_batch_train[:, time_step, :]\n",
        "    #print(\"shape of each time slice: {} \".format(x_t.shape))\n",
        "    #lbl_batch = val_data[:, time_step+1]\n",
        "  break;\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== batch number: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RnVuX2Zt_Ow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "798682f3-d1f8-4c6e-f99f-227e69846044"
      },
      "source": [
        "previous_decoder_state_fixed"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
              "array([15, 12, 37, 52, 16, 16, 12, 16, 12, 49, 56,  4, 42, 38, 17, 16, 52,\n",
              "       50,  3, 52, 12, 49,  1,  3, 52, 16, 10,  8, 13, 24,  8, 24, 16, 50,\n",
              "       16, 12, 61, 61, 61, 34, 16, 16, 24, 49, 61, 12, 29, 38,  4, 34, 24,\n",
              "       52, 63, 60, 13, 13, 42, 47, 24, 51, 16, 16, 50, 61, 52, 24, 61, 24,\n",
              "       56, 37,  3, 24, 49, 56, 24,  7, 24, 15,  8,  8, 13, 67, 16, 31,  3,\n",
              "       34, 63, 16, 13, 24, 15, 12, 24, 16, 40, 15, 34, 49, 12, 18, 63, 16,\n",
              "       12, 24,  8, 13, 34, 10, 18, 16, 16, 30, 61, 10, 24, 66, 15, 14, 49,\n",
              "       63, 42, 12, 12, 52, 13,  1, 52, 51], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zetSTm8AuzaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "e9a1b50e-6fdf-4cf9-a7e3-37a4bfcd7cf6"
      },
      "source": [
        "onehotencoded_prev_decoder_state = onehotencode(previous_decoder_state_fixed)\n",
        "onehotencoded_prev_decoder_state"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 68), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EXZEJG4ucJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "ff287970-917b-4e49-b571-de0bcace8d33"
      },
      "source": [
        "time_steps=200\n",
        "output_list = []\n",
        "for batch_num, (x_batch_train, val_data) in enumerate(zip(batched_onehotencoded_data,batched_vocab_data) ):\n",
        "  print(\"===== batch number: {}\".format(batch_num))\n",
        "  for time_step in range(time_steps):\n",
        "    #(128 * 68) dot product (68 * 128) ==> (128, 128)\n",
        "    curr_timestep_attention_onehot = tf.matmul(a=x_batch_train[:,time_step,:], b=onehotencoded_prev_decoder_state, transpose_b=True)\n",
        "\n",
        "    #Printing some stuff for checking\n",
        "    #print(curr_timestep_attention_onehot)\n",
        "    #print(tf.math.reduce_sum(curr_timestep_attention_onehot, axis=1, keepdims=False, name=None))\n",
        "\n",
        "    #Convert the onehot encoded output to categorical for attention\n",
        "    #(128 * 128) === reduce sum on axis 1 to check attention inside same record, using axis zero would take cross records sum\n",
        "    # (128 * 128) ===> (128 * 1) ==> one attention value per record per timestep\n",
        "    output_list.append(tf.math.reduce_sum(curr_timestep_attention_onehot, axis=1, keepdims=False, name=None))\n",
        "    \n",
        "  unscaled_outputs = tf.stack(output_list,axis = 1)\n",
        "  print(\"====== unscaled thing =============\")\n",
        "  print(unscaled_outputs)\n",
        "  print()\n",
        "  print(\" ===============. softmax thing ===========\")\n",
        "  softmax_output = tf.nn.softmax(unscaled_outputs, axis=1)\n",
        "  print(softmax_output)\n",
        "  print()\n",
        "  print(\"======== check whether softmax adds to one for final check, it adds to ne approx(numerical multiplier issues in matmul) ===========\")\n",
        "  print(tf.reduce_sum(softmax_output, axis=1))\n",
        "\n",
        "  #Print the below to check that softmax across axis = 0 doesn't sum to one for final check\n",
        "  #print(tf.reduce_sum(softmax_output, axis=0))\n",
        "  break;"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== batch number: 0\n",
            "====== unscaled thing =============\n",
            "tf.Tensor(\n",
            "[[ 0.  0. 11. ... 17.  2.  7.]\n",
            " [ 0.  5. 17. ...  7.  7. 14.]\n",
            " [ 0.  7.  1. ...  5. 17.  7.]\n",
            " ...\n",
            " [ 0.  3. 14. ...  3.  7.  5.]\n",
            " [ 0.  5. 17. ... 17.  1.  5.]\n",
            " [ 0. 17.  5. ...  7.  1.  5.]], shape=(128, 200), dtype=float32)\n",
            "\n",
            " ===============. softmax thing ===========\n",
            "tf.Tensor(\n",
            "[[1.7862440e-09 1.7862440e-09 1.0694983e-04 ... 4.3146640e-02\n",
            "  1.3198658e-08 1.9588545e-06]\n",
            " [1.3877071e-09 2.0595400e-07 3.3519998e-02 ... 1.5218056e-06\n",
            "  1.5218056e-06 1.6688624e-03]\n",
            " [1.6701229e-09 1.8315121e-06 4.5398649e-09 ... 2.4786820e-07\n",
            "  4.0341739e-02 1.8315121e-06]\n",
            " ...\n",
            " [1.4342060e-09 2.8806797e-08 1.7247822e-03 ... 2.8806797e-08\n",
            "  1.5727978e-06 2.1285504e-07]\n",
            " [1.2631630e-09 1.8747001e-07 3.0511642e-02 ... 3.0511642e-02\n",
            "  3.4336332e-09 1.8747001e-07]\n",
            " [1.5965517e-09 3.8564630e-02 2.3694928e-07 ... 1.7508315e-06\n",
            "  4.3398778e-09 2.3694928e-07]], shape=(128, 200), dtype=float32)\n",
            "\n",
            "======== check whether softmax adds to one for final check, it adds to ne approx(numerical multiplier issues in matmul) ===========\n",
            "tf.Tensor(\n",
            "[1.         1.0000001  1.0000001  0.99999994 1.         1.0000001\n",
            " 1.         0.99999994 1.         1.         1.         1.\n",
            " 1.         0.9999999  1.         1.         1.0000001  1.\n",
            " 1.0000001  1.         1.         1.0000002  1.         1.\n",
            " 1.         1.0000001  1.0000001  1.0000002  1.         1.0000001\n",
            " 1.         1.         1.0000001  1.         1.0000001  1.\n",
            " 1.         1.         1.         1.         1.         1.0000001\n",
            " 1.         1.         1.         1.         0.99999994 1.0000001\n",
            " 1.0000002  1.         1.         1.         0.99999994 1.\n",
            " 1.         1.         1.0000002  1.         0.9999999  1.\n",
            " 1.         1.         1.         1.         1.0000001  1.\n",
            " 1.0000002  0.99999994 1.         0.99999994 0.9999999  1.0000002\n",
            " 1.0000001  1.0000001  1.         1.         1.         1.0000001\n",
            " 1.0000001  1.0000002  1.0000001  1.         1.         1.0000001\n",
            " 1.         1.0000001  1.0000001  0.99999994 1.0000001  1.\n",
            " 1.0000001  1.0000001  1.         1.0000001  1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.0000001  0.99999994\n",
            " 0.99999994 1.         1.         1.         1.         1.0000002\n",
            " 1.0000001  1.         0.99999994 1.         1.         1.\n",
            " 1.         1.         0.99999994 0.99999994 0.9999999  1.0000001\n",
            " 1.         1.0000001 ], shape=(128,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}